{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "Seq2Seq_model_verification_without_force_teaching.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2a9e7d6"
      },
      "source": [
        "## Purpose of this notebook is to verify the seq2seq model (without force teaching) coding \n",
        "- tested with fixed sequence length"
      ],
      "id": "a2a9e7d6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf1a9946"
      },
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
      ],
      "id": "cf1a9946",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "158af215"
      },
      "source": [
        "import tensorflow as tf "
      ],
      "id": "158af215",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c7ee28e"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)"
      ],
      "id": "8c7ee28e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e00f3e67"
      },
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from numpy import array_equal\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense \n",
        "from keras.layers import Lambda\n",
        "from keras.layers import concatenate\n",
        "from keras import backend as K\n"
      ],
      "id": "e00f3e67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd98RN9r6g-c"
      },
      "source": [
        "##Dummy dataset creation \n",
        "- with fixed sequence length of 10"
      ],
      "id": "Gd98RN9r6g-c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "058cc448",
        "outputId": "7fb87854-f2eb-4132-dae5-4ad2b4adf19c"
      },
      "source": [
        "cd C:\\Users\\ASUS\\Desktop\\dataset-460-40"
      ],
      "id": "058cc448",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS\\Desktop\\dataset-460-40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eac20a50"
      },
      "source": [
        "#Function to generate a sequence of integers (e.g. from 0 to 499) \n",
        "def generate_sequence(length, n_unique):\n",
        "\treturn [randint(0, n_unique-1) for _ in range(length)]"
      ],
      "id": "eac20a50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db904a61"
      },
      "source": [
        "#n_unique -> no. of unique digits (0,1,2,3,4,,...,499) to be chosen for use in each sample of input sequence\n",
        "#n_samples -> total no. of samples in dataset\n",
        "\n",
        "#Function to return arrays of dataset for encoder input, decoder input and decoder output\n",
        "def get_dataset(n_unique, n_samples):\n",
        "\n",
        "    encoder_input = list()\n",
        "    decoder_input = list()\n",
        "    decoder_output = list()\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "\n",
        "        length = 10\n",
        "        #length = randint(20, 267)\n",
        "        \n",
        "        encoder_ip = list()\n",
        "        encoder_ip_x = generate_sequence(length, n_unique) #list of x-coordinates of encoder input\n",
        "        encoder_ip_y = generate_sequence(length, n_unique) #list y-coordinates of encoder input\n",
        "\n",
        "        for i in range(length):\n",
        "            coordinate_pair = (encoder_ip_x[i], encoder_ip_y[i])\n",
        "            encoder_ip.append(coordinate_pair)\n",
        "        while len(encoder_ip) < 10: \n",
        "          encoder_ip.append([500,500]) \n",
        "\n",
        "        x_sum = 0\n",
        "        x_coord_running_sum = list()  #list of x_coord running sum\n",
        "        for i in range(length):\n",
        "            x_sum = x_sum + encoder_ip[i][0]\n",
        "            x_coord_running_sum.append(x_sum)\n",
        "\n",
        "        y_sum = 0\n",
        "        y_coord_running_sum = list()  #list of y_coord running sum\n",
        "        for i in range(length):\n",
        "            y_sum = y_sum + encoder_ip[i][1]\n",
        "            y_coord_running_sum.append(y_sum)\n",
        "\n",
        "        decoder_op = list()\n",
        "        for i in range(length): \n",
        "            if (x_coord_running_sum[i] + y_coord_running_sum[i])%2 == 0: #if sum of x and y coord is even, output is even; else output is odd\n",
        "                op = 0\n",
        "            else:\n",
        "                op = 1\n",
        "            decoder_op.append(op)\n",
        "        while len(decoder_op) < 10:\n",
        "          decoder_op.append(0)\n",
        "\n",
        "        decoder_ip =  [2] + decoder_op[:-1] #decoder_ip is one time-step ahead of decoder_op\n",
        "\n",
        "        encoder_input.append(encoder_ip)\n",
        "        decoder_input.append(decoder_ip)\n",
        "        decoder_output.append(decoder_op)\n",
        "\n",
        "    X1=np.array(encoder_input)\n",
        "    X2=np.array(decoder_input).reshape(n_samples,10,1)\n",
        "    Y=np.array(decoder_output).reshape(n_samples,10,1)\n",
        "\n",
        "    #One-hot-encode\n",
        "    encoder_input_onehot=list()\n",
        "    for i in range(X2.shape[0]):\n",
        "        row=list()\n",
        "        for j in range(10):\n",
        "            row.append(X1[i][j][0])\n",
        "            row.append(X1[i][j][1])\n",
        "        encoder_input_onehot.append(row)\n",
        "    encoder_input_onehot = np.array(encoder_input_onehot)\n",
        "    encoder_input_onehot = to_categorical([encoder_input_onehot], num_classes=10)\n",
        "\n",
        "    decoder_input_onehot = to_categorical([X2], num_classes=3)\n",
        "    decoder_output_onehot = to_categorical([Y], num_classes=3)\n",
        "\n",
        "    encoder_input_onehot = encoder_input_onehot.reshape(n_samples,20,10)\n",
        "    decoder_input_onehot = decoder_input_onehot.reshape(n_samples,10,3)\n",
        "    decoder_output_onehot = decoder_output_onehot.reshape(n_samples,10,3)\n",
        "\n",
        "    return encoder_input_onehot, decoder_input_onehot, decoder_output_onehot\n",
        "   "
      ],
      "id": "db904a61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc53def0"
      },
      "source": [
        "n_unique = 10\n",
        "n_samples = 100000\n",
        "X1, _, Y = get_dataset(n_unique, n_samples)"
      ],
      "id": "dc53def0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80820d29",
        "outputId": "af473b20-cba5-4e47-fa52-f3008f4fabe3"
      },
      "source": [
        "print(X1.shape,Y.shape)"
      ],
      "id": "80820d29",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100000, 20, 10) (100000, 10, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d9043fa"
      },
      "source": [
        "n_unique = 10\n",
        "n_samples_valid = 10000\n",
        "X1_valid,_, Y_valid = get_dataset(n_unique, n_samples_valid)"
      ],
      "id": "4d9043fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd5dd8e9",
        "outputId": "49d199a3-d269-4dca-c0cf-907c4400ba7f"
      },
      "source": [
        "print(X1_valid.shape,Y_valid.shape)"
      ],
      "id": "cd5dd8e9",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 20, 10) (10000, 10, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "419bbbaf"
      },
      "source": [
        "#Setup decoder input data\n",
        "#decoder_input_data = np.zeros((num_samples, 1, n_features))\n",
        "X2 = np.zeros((n_samples, 1, 3))\n",
        "X2[:, 0, 0] = 1 "
      ],
      "id": "419bbbaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1e961f3"
      },
      "source": [
        "# Model creation and training"
      ],
      "id": "d1e961f3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3acf89f"
      },
      "source": [
        "encoder_inputs = Input(shape=(None, 10))\n",
        "encoder = LSTM(128, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(1, 3))\n",
        "decoder_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
        "decoder_dense = Dense(3, activation='softmax')\n",
        "\n",
        "all_outputs = []\n",
        "inputs = decoder_inputs\n",
        "for _ in range(10):\n",
        "    outputs, state_h, state_c = decoder_lstm(inputs, initial_state=states)\n",
        "    outputs = decoder_dense(outputs)\n",
        "    all_outputs.append(outputs)\n",
        "    inputs = outputs\n",
        "    states = [state_h, state_c]\n",
        "\n",
        "decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "id": "a3acf89f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "245abc34",
        "outputId": "b07aa507-d17b-4eda-949f-8e7d8d483670"
      },
      "source": [
        "model.fit([X1, X2], Y, batch_size=32, epochs=100)"
      ],
      "id": "245abc34",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3125/3125 [==============================] - 67s 19ms/step - loss: 0.6953 - accuracy: 0.4997\n",
            "Epoch 2/100\n",
            "3125/3125 [==============================] - 60s 19ms/step - loss: 0.6937 - accuracy: 0.4997\n",
            "Epoch 3/100\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.6935 - accuracy: 0.49970s - loss: 0.6935 - \n",
            "Epoch 4/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.6934 - accuracy: 0.5002\n",
            "Epoch 5/100\n",
            "3125/3125 [==============================] - 67s 22ms/step - loss: 0.6934 - accuracy: 0.5006\n",
            "Epoch 6/100\n",
            "3125/3125 [==============================] - 69s 22ms/step - loss: 0.6933 - accuracy: 0.5010\n",
            "Epoch 7/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.6933 - accuracy: 0.5003\n",
            "Epoch 8/100\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.6933 - accuracy: 0.5013\n",
            "Epoch 9/100\n",
            "3125/3125 [==============================] - 67s 21ms/step - loss: 0.6932 - accuracy: 0.5006\n",
            "Epoch 10/100\n",
            "3125/3125 [==============================] - 68s 22ms/step - loss: 0.6932 - accuracy: 0.5008\n",
            "Epoch 11/100\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.6931 - accuracy: 0.5035\n",
            "Epoch 12/100\n",
            "3125/3125 [==============================] - 64s 21ms/step - loss: 0.6452 - accuracy: 0.54380s - loss: 0.6452 - accuracy: 0.54\n",
            "Epoch 13/100\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.5593 - accuracy: 0.6029\n",
            "Epoch 14/100\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.5130 - accuracy: 0.6363\n",
            "Epoch 15/100\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.4785 - accuracy: 0.6648\n",
            "Epoch 16/100\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.4287 - accuracy: 0.7021\n",
            "Epoch 17/100\n",
            "3125/3125 [==============================] - 67s 21ms/step - loss: 0.3914 - accuracy: 0.7290\n",
            "Epoch 18/100\n",
            "3125/3125 [==============================] - 64s 21ms/step - loss: 0.3698 - accuracy: 0.74340s - loss: 0.3698 - accuracy: 0.\n",
            "Epoch 19/100\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.3468 - accuracy: 0.7632\n",
            "Epoch 20/100\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.3107 - accuracy: 0.7895\n",
            "Epoch 21/100\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.2752 - accuracy: 0.8157\n",
            "Epoch 22/100\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.2398 - accuracy: 0.8435\n",
            "Epoch 23/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.2011 - accuracy: 0.87201s - los - ETA: 0s - loss: 0.2012 \n",
            "Epoch 24/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.1669 - accuracy: 0.8977\n",
            "Epoch 25/100\n",
            "3125/3125 [==============================] - 64s 21ms/step - loss: 0.1357 - accuracy: 0.9202\n",
            "Epoch 26/100\n",
            "3125/3125 [==============================] - 70s 22ms/step - loss: 0.1126 - accuracy: 0.9379\n",
            "Epoch 27/100\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.0830 - accuracy: 0.9548\n",
            "Epoch 28/100\n",
            "3125/3125 [==============================] - 69s 22ms/step - loss: 0.0666 - accuracy: 0.9645\n",
            "Epoch 29/100\n",
            "3125/3125 [==============================] - 70s 22ms/step - loss: 0.0611 - accuracy: 0.9699\n",
            "Epoch 30/100\n",
            "3125/3125 [==============================] - 77s 25ms/step - loss: 0.0376 - accuracy: 0.9820\n",
            "Epoch 31/100\n",
            "3125/3125 [==============================] - 70s 23ms/step - loss: 0.0272 - accuracy: 0.9880\n",
            "Epoch 32/100\n",
            "3125/3125 [==============================] - 79s 25ms/step - loss: 0.0325 - accuracy: 0.9855\n",
            "Epoch 33/100\n",
            "3125/3125 [==============================] - 76s 24ms/step - loss: 0.0194 - accuracy: 0.9913\n",
            "Epoch 34/100\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.0169 - accuracy: 0.9926\n",
            "Epoch 35/100\n",
            "3125/3125 [==============================] - 74s 24ms/step - loss: 0.0150 - accuracy: 0.9935\n",
            "Epoch 36/100\n",
            "3125/3125 [==============================] - 71s 23ms/step - loss: 0.0123 - accuracy: 0.9948\n",
            "Epoch 37/100\n",
            "3125/3125 [==============================] - 72s 23ms/step - loss: 0.0130 - accuracy: 0.9946\n",
            "Epoch 38/100\n",
            "3125/3125 [==============================] - 71s 23ms/step - loss: 0.0106 - accuracy: 0.9956\n",
            "Epoch 39/100\n",
            "3125/3125 [==============================] - 71s 23ms/step - loss: 0.0096 - accuracy: 0.9960\n",
            "Epoch 40/100\n",
            "3125/3125 [==============================] - 70s 22ms/step - loss: 0.0088 - accuracy: 0.9964\n",
            "Epoch 41/100\n",
            "3125/3125 [==============================] - 70s 23ms/step - loss: 0.0081 - accuracy: 0.9967\n",
            "Epoch 42/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0069 - accuracy: 0.9972\n",
            "Epoch 43/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0062 - accuracy: 0.99740s - loss: 0.0062 - accuracy:  - ETA: 0s - loss: 0.0062 \n",
            "Epoch 44/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0070 - accuracy: 0.9973\n",
            "Epoch 45/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0050 - accuracy: 0.9980\n",
            "Epoch 46/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0056 - accuracy: 0.9979A - ETA: 0s - loss: 0.0056 - accuracy: 0.\n",
            "Epoch 47/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0051 - accuracy: 0.99810s - loss: 0.0051 - accuracy: 0.\n",
            "Epoch 48/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0042 - accuracy: 0.99843s - loss: 0.0041 \n",
            "Epoch 49/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0034 - accuracy: 0.99870s - loss:\n",
            "Epoch 50/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0043 - accuracy: 0.99850s - loss: 0.0043 - accuracy: 0.99 - ETA: 0s - loss: 0.0043 - ac\n",
            "Epoch 51/100\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.0038 - accuracy: 0.9987: 0s - loss: 0.0038 - accuracy: 0.99\n",
            "Epoch 52/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0032 - accuracy: 0.9990\n",
            "Epoch 53/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0033 - accuracy: 0.9990\n",
            "Epoch 54/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0032 - accuracy: 0.9990: 36s - loss: 0.0029 - acc - ETA: 35s - los - ET\n",
            "Epoch 55/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 56/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0023 - accuracy: 0.9993\n",
            "Epoch 57/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0022 - accuracy: 0.99942s - loss: 0.0023 -  - ETA\n",
            "Epoch 58/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0027 - accuracy: 0.9992 ETA: 0s - loss: 0.0027 \n",
            "Epoch 59/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0016 - accuracy: 0.9995 ETA: 1:00 - loss: 9.2642e-04 - acc\n",
            "Epoch 60/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0021 - accuracy: 0.99941s - loss: 0.0 - ETA: 0s - loss: 0.0021 \n",
            "Epoch 61/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0018 - accuracy: 0.9996\n",
            "Epoch 62/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0021 - accuracy: 0.9994 ETA - ETA: 0s - loss: 0.0021 - accu\n",
            "Epoch 63/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0014 - accuracy: 0.9996\n",
            "Epoch 64/100\n",
            "3125/3125 [==============================] - 64s 21ms/step - loss: 0.0018 - accuracy: 0.9995: 10s - loss: 0 - ETA: 4s - loss: 0.0 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.0018 - accura\n",
            "Epoch 65/100\n",
            "3125/3125 [==============================] - 64s 21ms/step - loss: 0.0014 - accuracy: 0.99960s - loss: 0.0014 - ac\n",
            "Epoch 66/100\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Epoch 67/100\n",
            "3125/3125 [==============================] - 64s 21ms/step - loss: 9.4917e-04 - accuracy: 0.9997: 45s - lo - ETA: 1s\n",
            "Epoch 68/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0014 - accuracy: 0.9996\n",
            "Epoch 69/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 9.6991e-04 - accuracy: 0.99971s - los - ETA: 0s - loss: 9.4457e-04 \n",
            "Epoch 70/100\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Epoch 71/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 72/100\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.0012 - accuracy: 0.9997: 39s - loss: 0.0012 - - ETA: 0s - loss: 0.0\n",
            "Epoch 73/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0014 - accuracy: 0.99960s - loss: 0.0014 - accuracy: 0. - ETA: 0s - loss: 0.0014 - accuracy: \n",
            "Epoch 74/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 9.5547e-04 - accuracy: 0.9998 loss: 0.0010 - accura - ETA: 2s - loss: 9.9646e-04 - ac - ETA: 0s - loss:\n",
            "Epoch 75/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0017 - accuracy: 0.99954s - los - ETA: \n",
            "Epoch 76/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 7.9639e-04 - accuracy: 0.9998\n",
            "Epoch 77/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0014 - accuracy: 0.99960s - loss: 0.0015 \n",
            "Epoch 78/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0011 - accuracy: 0.99971s - loss: 0.001 - E\n",
            "Epoch 79/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0014 - accuracy: 0.9996\n",
            "Epoch 80/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0016 - accuracy: 0.9996\n",
            "Epoch 81/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 8.0343e-04 - accuracy: 0.9998\n",
            "Epoch 82/100\n",
            "3125/3125 [==============================] - 64s 20ms/step - loss: 0.0011 - accuracy: 0.9997 ETA: - ETA: 47s - loss: 5.4 - ETA: 42s - loss: 0.002 - ETA: 2s - loss: 0.0011 - ac - ETA:  - ETA: 0s - loss: 0.001\n",
            "Epoch 83/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 6.9817e-04 - accuracy: 0.9998s - los - ETA: 13s - loss: 7.8625e-04 - accuracy - E - ETA: 10s - loss: 7.4571e-04 - accuracy: 0.99 - ETA: 10s - loss: 7.4 - E - ETA: 0s - loss: 6\n",
            "Epoch 84/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0020 - accuracy: 0.9995: 2s - loss: 0.0020 - accu - ETA: 0s - loss: 0.0020 \n",
            "Epoch 85/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 6.7262e-04 - accuracy: 0.9998s - loss: 0.0013 \n",
            "Epoch 86/100\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.0012 - accuracy: 0.9998: 19s - ETA: 0s - loss: 0.0012 - accuracy: 0.99\n",
            "Epoch 87/100\n",
            "3125/3125 [==============================] - 69s 22ms/step - loss: 9.2467e-04 - accuracy: 0.9998\n",
            "Epoch 88/100\n",
            "3125/3125 [==============================] - 110s 35ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 89/100\n",
            "3125/3125 [==============================] - 141s 45ms/step - loss: 0.0014 - accuracy: 0.9996\n",
            "Epoch 90/100\n",
            "3125/3125 [==============================] - 126s 40ms/step - loss: 7.7668e-04 - accuracy: 0.9998\n",
            "Epoch 91/100\n",
            "3125/3125 [==============================] - 126s 40ms/step - loss: 5.8505e-04 - accuracy: 0.9999\n",
            "Epoch 92/100\n",
            "3125/3125 [==============================] - 116s 37ms/step - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 93/100\n",
            "3125/3125 [==============================] - 120s 38ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 94/100\n",
            "3125/3125 [==============================] - 119s 38ms/step - loss: 5.8000e-04 - accuracy: 0.9998\n",
            "Epoch 95/100\n",
            "3125/3125 [==============================] - 138s 44ms/step - loss: 6.7646e-04 - accuracy: 0.9998\n",
            "Epoch 96/100\n",
            "3125/3125 [==============================] - 116s 37ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 97/100\n",
            "3125/3125 [==============================] - 118s 38ms/step - loss: 7.9609e-04 - accuracy: 0.9998\n",
            "Epoch 98/100\n",
            "3125/3125 [==============================] - 116s 37ms/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 99/100\n",
            "3125/3125 [==============================] - 118s 38ms/step - loss: 6.8113e-04 - accuracy: 0.9998\n",
            "Epoch 100/100\n",
            "3125/3125 [==============================] - 111s 36ms/step - loss: 7.9281e-04 - accuracy: 0.9998\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x25754e43898>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8baabe82"
      },
      "source": [
        "## Evaluate with test data"
      ],
      "id": "8baabe82"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4459fdc9"
      },
      "source": [
        "def one_hot_decode(encoded_seq):\n",
        "\treturn [argmax(vector) for vector in encoded_seq]"
      ],
      "id": "4459fdc9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "948c9f03"
      },
      "source": [
        "n_unique = 10\n",
        "n_samples = 1\n",
        "X1_test,_, y_test = get_dataset(n_unique, n_samples)"
      ],
      "id": "948c9f03",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "496f5746"
      },
      "source": [
        "X2_test = np.zeros((n_samples, 1, 3))\n",
        "X2_test[:, 0, 0] = 1 "
      ],
      "id": "496f5746",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a9ffde5"
      },
      "source": [
        "prediction = model.predict([X1_test, X2_test])"
      ],
      "id": "6a9ffde5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec718355"
      },
      "source": [
        "prediction = prediction[0]"
      ],
      "id": "ec718355",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc98de96"
      },
      "source": [
        "prediction = one_hot_decode(prediction)"
      ],
      "id": "fc98de96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46a2f734",
        "outputId": "5bb9d573-d1c7-4826-eafa-bd5f0293ecff"
      },
      "source": [
        "prediction"
      ],
      "id": "46a2f734",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 1, 1, 1, 1, 1, 0]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd8569cf"
      },
      "source": [
        "truth = one_hot_decode(y_test[0])"
      ],
      "id": "dd8569cf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8590f011",
        "outputId": "d60661bf-847f-4571-a8b2-5fef1f053d2c"
      },
      "source": [
        "truth"
      ],
      "id": "8590f011",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 1, 1, 1, 1, 1, 0]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edb308c6"
      },
      "source": [
        ""
      ],
      "id": "edb308c6",
      "execution_count": null,
      "outputs": []
    }
  ]
}